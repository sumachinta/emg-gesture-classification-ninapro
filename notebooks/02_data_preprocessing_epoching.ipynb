{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292881d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "parentDir = Path.cwd().parent\n",
    "sys.path.insert(0, str(parentDir))\n",
    "from utils.preprocess import load_ninapro_data, preprocess_emg, epoch_data\n",
    "from utils.plotting_helpers import plot_gesture_trace\n",
    "dataPath = parentDir / \"data\" / \"raw\" / \"ninapro-db2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bcc30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject_number = 25\n",
    "# exercise_number = 1\n",
    "# channel_to_plot = 2\n",
    "\n",
    "# saveFigs = True\n",
    "# emg, stimulus, repetition, time, Fs = load_ninapro_data(subject_number=subject_number, exercise_number=exercise_number, dataPath=dataPath)\n",
    "# filtered_emg = preprocess_emg(emg[:, channel_to_plot], Fs, smoothen=True, lowcut=20.0, highcut=450.0, smooth_window=0.05, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f0f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # Plot raw and filtered EMG signals for comparison\n",
    "\n",
    "# plot_startTime = 0  # in seconds\n",
    "# plot_endTime = 240   # in seconds\n",
    "\n",
    "# start_index = int(plot_startTime * Fs)\n",
    "# end_index = int(plot_endTime * Fs)\n",
    "# unique_gestures = np.unique(stimulus)\n",
    "\n",
    "# fig, axs = plt.subplots(2,1, figsize=((plot_endTime - plot_startTime)/15, 4), sharex=True)\n",
    "# axs[0].plot(time[start_index:end_index], emg[start_index:end_index, channel_to_plot], color='blue', label='Raw EMG', alpha=0.5)\n",
    "# axs[1].plot(time[start_index:end_index], filtered_emg[start_index:end_index], color='red', label='Filtered EMG', alpha=0.5)\n",
    "# plt.suptitle(f'EMG Signal (Channel {channel_to_plot} exercise {exercise_number}, subject {subject_number})')\n",
    "# plt.xlabel('Time (s)')\n",
    "# axs[0].set_title('Raw EMG Signal')\n",
    "# axs[1].set_title('Filtered EMG Signal')\n",
    "\n",
    "# # Plot all gesture repetitions\n",
    "# for gesture_id in unique_gestures:\n",
    "#     if gesture_id == 0:\n",
    "#             continue # Skip rest gesture\n",
    "#     for repetition_id in range(1, 7):  #6 repetitions\n",
    "#         # Find start and end indices of the gesture repetition\n",
    "#         mask = (stimulus == gesture_id) & (repetition == repetition_id)\n",
    "#         if np.any(mask):\n",
    "#             start_idx = np.where(mask)[0][0]\n",
    "#             end_idx = np.where(mask)[0][-1]\n",
    "#             ## Skip spans that are completely outside the plotted window\n",
    "#             if end_idx < start_index or start_idx > end_index - 1:\n",
    "#                 continue\n",
    "#             # Clamp to the plotting window\n",
    "#             start_idx = max(start_idx, start_index)\n",
    "#             end_idx   = min(end_idx,   end_index - 1)\n",
    "#         axs[0].axvspan(time[start_idx], time[end_idx], color=plt.cm.tab20(gesture_id % 20), alpha=0.3, label=f' {gesture_id}')\n",
    "#         axs[1].axvspan(time[start_idx], time[end_idx], color=plt.cm.tab20(gesture_id % 20), alpha=0.3, label=f' {gesture_id}')\n",
    "# # plt.ylabel('Amplitude')\n",
    "# # plt.legend()\n",
    "# plt.tight_layout()\n",
    "# if saveFigs:    \n",
    "#     plt.savefig(parentDir / \"results\" / \"figures\" / f\"emg_preprocessing_subject{subject_number}_exercise{exercise_number}_channel{channel_to_plot}.png\", dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d175b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gesture_durations_df = pd.DataFrame(columns=[\"Subject\", \"Gesture\", \"Repetition\", \"Duration\"])\n",
    "# gesture_durations = []\n",
    "# emg_clean = np.zeros_like(emg)\n",
    "# windowTimeS = 1  # in seconds\n",
    "\n",
    "# # Go through all subjects and save duration of each gesture and each repetition\n",
    "# for subject_number in range(1,41):\n",
    "#     print(f\"Processing subject {subject_number}...\")\n",
    "    \n",
    "#     emg, stimulus, repetition, time, Fs = load_ninapro_data(subject_number=subject_number, exercise_number=exercise_number, dataPath=dataPath)\n",
    "#     emg_clean = np.zeros_like(emg)\n",
    "\n",
    "#     for ch in range(emg.shape[1]):\n",
    "#         emg_clean[:, ch] = preprocess_emg(emg[:, ch], Fs, smoothen=True, lowcut=20.0, highcut=450.0, smooth_window=0.05, normalize=True)\n",
    "#     for gesture in np.unique(stimulus):\n",
    "#         if gesture == 0:\n",
    "#             continue\n",
    "#         for rep in range(1, 7):\n",
    "#             indices = np.where((stimulus == gesture) & (repetition == rep))[0]\n",
    "#             if len(indices) == 0:\n",
    "#                 continue\n",
    "#             # duration = time[indices[-1]] - time[indices[0]]\n",
    "#             duration = len(indices) / Fs  # in seconds\n",
    "#             gesture_durations.append({\"Subject\": subject_number, \"Gesture\": gesture, \"Repetition\": rep, \"Duration\": duration})\n",
    "#             # Epoch data for each gesture and repetition for ML purposes\n",
    "            \n",
    "\n",
    "# gesture_durations_df = pd.DataFrame(gesture_durations)\n",
    "# gesture_durations_df.to_csv(parentDir / \"data\" / \"processed\" / \"gesture_durations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba94ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot durations per gesture as a box plot\n",
    "# import seaborn as sns\n",
    "# plt.figure(figsize=(7, 4))\n",
    "# sns.boxplot(x=\"Gesture\", y=\"Duration\", data=gesture_durations_df, palette=\"Set2\")\n",
    "# plt.xlabel('Gesture')\n",
    "# plt.ylabel('Duration (s)')\n",
    "# plt.title('Gesture Durations')\n",
    "# plt.tight_layout()\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# if saveFigs:    \n",
    "#     plt.savefig(parentDir / \"results\" / \"figures\" / f\"gesture_durations_summary.png\", dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2900b63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot cleaned average emg traces for each gesture for a given subject, exercise, and channel\n",
    "# subject_number = 28\n",
    "# exercise_number = 1\n",
    "# gesture_to_plot = 6\n",
    "# channel_to_plot = 5\n",
    "# duration_s = 3  # seconds\n",
    "\n",
    "# emg, stimulus, repetition, time, Fs = load_ninapro_data(subject_number=subject_number, exercise_number=exercise_number, dataPath=dataPath)\n",
    "# filtered_emg = preprocess_emg(emg[:, channel_to_plot], Fs, smoothen=True, lowcut=20.0, highcut=450.0, smooth_window=0.05, normalize=True)\n",
    "\n",
    "# emg_repetitions = np.zeros((0, int(duration_s * Fs)))  # Initialize empty array for storing epochs\n",
    "# for repetition_id in range(1, 7):  #6 repetitions\n",
    "#     # Find start and end indices of the gesture repetition\n",
    "#     mask = (stimulus == gesture_to_plot) & (repetition == repetition_id)\n",
    "#     if np.any(mask):\n",
    "#         start_idx = np.where(mask)[0][0]\n",
    "#         end_idx = np.where(mask)[0][-1]\n",
    "#         if end_idx - start_idx < int(duration_s * Fs):\n",
    "#             continue  # Skip if the gesture duration is less than desired duration\n",
    "#         # Clamp to desired duration\n",
    "#         end_idx = start_idx + int(duration_s * Fs)\n",
    "#         epoch_time = time[start_idx:end_idx] - time[start_idx]\n",
    "#         epoch_emg = filtered_emg[start_idx:end_idx]\n",
    "#         emg_repetitions = np.vstack((emg_repetitions, epoch_emg[np.newaxis, :]))  # Add new epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f63d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot mean and sem of the emg repetitions\n",
    "# mean_emg = np.mean(emg_repetitions, axis=0)\n",
    "# sem_emg = np.std(emg_repetitions, axis=0) / np.sqrt(emg_repetitions.shape[0])\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# plt.plot(epoch_time, mean_emg, label='Mean EMG')\n",
    "# plt.fill_between(epoch_time, mean_emg - sem_emg, mean_emg + sem_emg, alpha=0.3, label='±1 SEM')\n",
    "# plt.title(f'Subject {subject_number}, Exercise {exercise_number}, Gesture {gesture_to_plot}, Channel {channel_to_plot}')\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('EMG Amplitude (normalized)')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# # if saveFigs:    \n",
    "# #     plt.savefig(parentDir / \"results\" / \"figures\" / f\"emg_average_subject{subject_number}_exercise{exercise_number}_gesture{gesture_to_plot}_channel{channel_to_plot}.png\", dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75df9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot cleaned average emg traces for each gesture for all subjects (1 trace for each subject), exercise, and channel\n",
    "# exercise_number = 1\n",
    "# gesture_to_plot = 6\n",
    "# channel_to_plot = 5\n",
    "# duration_s = 3  # seconds\n",
    "\n",
    "# emg_mean_subject = np.zeros((41, int(duration_s * Fs)))  \n",
    "# for subject_number in range(1,41):\n",
    "#     print(f\"Processing subject {subject_number}...\")\n",
    "#     emg, stimulus, repetition, time, Fs = load_ninapro_data(subject_number=subject_number, exercise_number=exercise_number, dataPath=dataPath)\n",
    "#     filtered_emg = preprocess_emg(emg[:, channel_to_plot], Fs, smoothen=True, lowcut=20.0, highcut=450.0, smooth_window=0.05, normalize=True)\n",
    "\n",
    "#     emg_repetitions = np.zeros((0, int(duration_s * Fs)))  # Initialize empty array for storing epochs\n",
    "#     for repetition_id in range(1, 7):  #6 repetitions\n",
    "#         # Find start and end indices of the gesture repetition\n",
    "#         mask = (stimulus == gesture_to_plot) & (repetition == repetition_id)\n",
    "#         if np.any(mask):\n",
    "#             start_idx = np.where(mask)[0][0]\n",
    "#             end_idx = np.where(mask)[0][-1]\n",
    "#             if end_idx - start_idx < int(duration_s * Fs):\n",
    "#                 continue  # Skip if the gesture duration is less than desired duration\n",
    "#             # Clamp to desired duration\n",
    "#             end_idx = start_idx + int(duration_s * Fs)\n",
    "#             epoch_time = time[start_idx:end_idx] - time[start_idx]\n",
    "#             epoch_emg = filtered_emg[start_idx:end_idx]\n",
    "#             emg_repetitions = np.vstack((emg_repetitions, epoch_emg[np.newaxis, :]))  # Add new epoch\n",
    "#     if emg_repetitions.shape[0] > 0:\n",
    "#         emg_mean_subject[subject_number-1, :] = np.mean(emg_repetitions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0deb754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot mean and sem of the emg across subjects\n",
    "# mean_emg = np.mean(emg_mean_subject, axis=0)\n",
    "# sem_emg = np.std(emg_mean_subject, axis=0) / np.sqrt(emg_mean_subject.shape[0])\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "# axs[0].plot(epoch_time, mean_emg, label='Mean EMG')\n",
    "# axs[0].fill_between(epoch_time, mean_emg - sem_emg, mean_emg + sem_emg, alpha=0.3, label='±1 SEM')\n",
    "# axs[0].set_title(f'Gesture {gesture_to_plot}, Channel {channel_to_plot}, all subjects')\n",
    "# axs[0].set_xlabel('Time (s)')\n",
    "# axs[0].set_ylabel('EMG Amplitude (normalized)')\n",
    "\n",
    "# # Plot all individual subject traces\n",
    "# for subject_number in range(1,41):\n",
    "#     axs[1].plot(epoch_time, emg_mean_subject[subject_number-1, :], alpha=0.5, label=f'Subject {subject_number}')\n",
    "# axs[1].set_title(f'Gesture {gesture_to_plot}, Channel {channel_to_plot}, all subjects')\n",
    "# axs[1].set_xlabel('Time (s)')\n",
    "# axs[1].set_ylabel('EMG Amplitude (normalized)') \n",
    "# # plt.legend()\n",
    "# plt.tight_layout()\n",
    "# # if saveFigs:    \n",
    "# #     plt.savefig(parentDir / \"results\" / \"figures\" / f\"emg_average_subject{subject_number}_exercise{exercise_number}_gesture{gesture_to_plot}_channel{channel_to_plot}.png\", dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efa76024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fs=2000 Hz, channels=12, gestures(all)=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[T=200 ms] Processing subject 1...\n",
      "[T=200 ms] Processing subject 2...\n",
      "[T=200 ms] Processing subject 3...\n",
      "[T=200 ms] Processing subject 4...\n",
      "[T=200 ms] Processing subject 5...\n",
      "[T=200 ms] Processing subject 6...\n",
      "[T=200 ms] Processing subject 7...\n",
      "[T=200 ms] Processing subject 8...\n",
      "[T=200 ms] Processing subject 9...\n",
      "[T=200 ms] Processing subject 10...\n",
      "[T=200 ms] Processing subject 11...\n",
      "[T=200 ms] Processing subject 12...\n",
      "[T=200 ms] Processing subject 13...\n",
      "[T=200 ms] Processing subject 14...\n",
      "[T=200 ms] Processing subject 15...\n",
      "[T=200 ms] Processing subject 16...\n",
      "[T=200 ms] Processing subject 17...\n",
      "[T=200 ms] Processing subject 18...\n",
      "[T=200 ms] Processing subject 19...\n",
      "[T=200 ms] Processing subject 20...\n",
      "[T=200 ms] Processing subject 21...\n",
      "[T=200 ms] Processing subject 22...\n",
      "[T=200 ms] Processing subject 23...\n",
      "[T=200 ms] Processing subject 24...\n",
      "[T=200 ms] Processing subject 25...\n",
      "[T=200 ms] Processing subject 26...\n",
      "[T=200 ms] Processing subject 27...\n",
      "[T=200 ms] Processing subject 28...\n",
      "[T=200 ms] Processing subject 29...\n",
      "[T=200 ms] Processing subject 30...\n",
      "[T=200 ms] Processing subject 31...\n",
      "[T=200 ms] Processing subject 32...\n",
      "[T=200 ms] Processing subject 33...\n",
      "[T=200 ms] Processing subject 34...\n",
      "[T=200 ms] Processing subject 35...\n",
      "[T=200 ms] Processing subject 36...\n",
      "[T=200 ms] Processing subject 37...\n",
      "[T=200 ms] Processing subject 38...\n",
      "[T=200 ms] Processing subject 39...\n",
      "[T=200 ms] Processing subject 40...\n",
      "Saved: /Users/suma/Documents/emg-gesture-classification-ninapro/data/processed/ninapro_ex1_win200_ms_step50_ms_exclude_rest.npz | X(358358, 12, 400), kept windows=358358\n"
     ]
    }
   ],
   "source": [
    "#Sliding-window epoch extraction with majority voting labeling\n",
    "\n",
    "# Parameters\n",
    "window_s_list = [0.20]               # [0.10, 0.15, 0.20, 0.25]   # T in seconds\n",
    "data_out_prefix = \"ninapro_ex{}_win{}_ms_step{}_ms_exclude_rest\".format\n",
    "\n",
    "\n",
    "for window_s in window_s_list:\n",
    "    ds = epoch_data(\n",
    "        dataPath=dataPath,\n",
    "        exercise_number=1,\n",
    "        subjects=range(1, 41),\n",
    "        window_s=window_s,\n",
    "        step_s=0.05,\n",
    "        majority_threshold=0.999,\n",
    "        include_rest=False\n",
    "    )\n",
    "\n",
    "    out_name = data_out_prefix(ds.meta.exercise_number, int(ds.meta.win_s*1000), int(ds.meta.step_s*1000))\n",
    "    out_path = parentDir / \"data\" / \"processed\" / f\"{out_name}.npz\"\n",
    "\n",
    "    np.savez_compressed(\n",
    "        out_path,\n",
    "        X=ds.X,                         # (N, C, L)\n",
    "        y=ds.y,                         # gesture label per window (includes 0 if include_rest=True)\n",
    "        subject_ids=ds.subject_ids,     # (N,)\n",
    "        rep_ids=ds.rep_ids,             # (N,)\n",
    "        t0=ds.t0,                       # window start time (s)\n",
    "        coverage=ds.coverage,           # majority coverage fraction in window\n",
    "        lag_s=ds.lag_s,                 # lag from segment start (s)\n",
    "        Fs=ds.meta.Fs,\n",
    "        n_channels=ds.meta.n_channels,\n",
    "        L=np.array(ds.meta.win, int),        # window length in samples\n",
    "        Ld=np.array(ds.meta.step, int),      # step in samples\n",
    "        T_ms=np.array(int(ds.meta.win_s*1000), int),\n",
    "        S_ms=np.array(int(ds.meta.step_s*1000), int),\n",
    "        gesture_ids_all=ds.meta.gesture_ids_full,  # gesture vocabulary (possibly incl. 0)\n",
    "        exercise_number=np.array(ds.meta.exercise_number, int),\n",
    "        include_rest=np.array(int(ds.meta.include_rest), int),\n",
    "        majority_threshold=np.array(ds.meta.majority_threshold, float),\n",
    "    )\n",
    "    print(f\"Saved: {out_path} | X{ds.X.shape}, kept windows={ds.X.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bfbcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 1) One subject’s gesture 6 on channel 5\n",
    "# plot_gesture_trace(f\"{parentDir}/data/processed/ninapro_ex1_win200_ms_step50_ms.npz\",\n",
    "#                    gesture_label=6, subject=1, channel=1)\n",
    "\n",
    "# # 2) All-subjects (subject-balanced) gesture 6 on channel 5\n",
    "# plot_gesture_trace(f\"{parentDir}/data/processed/ninapro_ex1_win200_ms_step50_ms.npz\",\n",
    "#                    gesture_label=6, subject=None, channel=1, subject_balanced=True)\n",
    "\n",
    "# plot_gesture_trace(f\"{parentDir}/data/processed/ninapro_ex1_win200_ms_step50_ms.npz\",\n",
    "#                    gesture_label=0, subject=None, channel=1, subject_balanced=True)\n",
    "\n",
    "# # 3) All-subjects pooled (each window equal weight)\n",
    "# plot_gesture_trace(f\"{parentDir}/data/processed/ninapro_ex1_win200_ms_step50_ms.npz\",\n",
    "#                    gesture_label=6, subject=None, channel=1, subject_balanced=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b1af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emg-decode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
